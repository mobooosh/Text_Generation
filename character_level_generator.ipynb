{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31492e59-aca5-4477-a90b-9fb4a3c380b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 07:57:54.103188: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-06 07:57:54.370032: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-06 07:57:54.370127: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-06 07:57:54.420995: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-06 07:57:54.483093: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-06 07:57:55.266094: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '15'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230b837e-1c64-4185-ab93-411f39e1f14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Part</th>\n",
       "      <th>Bait</th>\n",
       "      <th>Mesra</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>به نام خداوند جان و خرد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>کز این برتر اندیشه بر نگذرد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>خداوند نام و خداوند جای</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>خداوند روزی ده رهنمای</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>خداوند کیوان و گَردان سپهر</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Chapter  Part  Bait  Mesra                         Text\n",
       "0        1     1     1      1      به نام خداوند جان و خرد\n",
       "1        1     1     1      2  کز این برتر اندیشه بر نگذرد\n",
       "2        1     1     2      1      خداوند نام و خداوند جای\n",
       "3        1     1     2      2        خداوند روزی ده رهنمای\n",
       "4        1     1     3      1   خداوند کیوان و گَردان سپهر"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#file_path = pd.read_csv('shahname.csv')\n",
    "file_path = pd.read_csv('shahname.csv', encoding='utf-8')\n",
    "file_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca431ea-9f5f-4ba1-ac45-a0536417c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_data = file_path['Text']\n",
    "\n",
    "combined_data = ','.join(column_data.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f7e4e9f-53e6-4d2a-bf6e-8fe601982df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'به نام خداوند جان و خرد,کز این برتر اندیشه بر نگذرد,خداوند نام و خداوند جای,خداوند روزی ده رهنمای,خدا'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data[:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa260555-6e20-429d-b946-557f0fd10764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 2565041 characters\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of text: {len(combined_data)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f368b0-c74f-415a-ae9b-760083599c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(combined_data))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f08e88b0-d00c-4923-8ccb-853a8b5a825e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ! ( ) , :   « » ، ؛ ؟ ء آ أ ؤ ئ ا ب ت ث ج ح خ د ذ ر ز س ش ص ض ط ظ ع غ ف ق ل م ن ه و ي َ ُ ِ ّ ْ ٔ پ چ ژ ک گ ی ‌ "
     ]
    }
   ],
   "source": [
    "for v in vocab:\n",
    "    print(f'{v}', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df81f1da-eccf-44a3-96a3-874f2581bf68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " '!',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ':',\n",
       " '\\xa0',\n",
       " '«',\n",
       " '»',\n",
       " '،',\n",
       " '؛',\n",
       " '؟',\n",
       " 'ء',\n",
       " 'آ',\n",
       " 'أ',\n",
       " 'ؤ',\n",
       " 'ئ',\n",
       " 'ا',\n",
       " 'ب',\n",
       " 'ت',\n",
       " 'ث',\n",
       " 'ج',\n",
       " 'ح',\n",
       " 'خ',\n",
       " 'د',\n",
       " 'ذ',\n",
       " 'ر',\n",
       " 'ز',\n",
       " 'س',\n",
       " 'ش',\n",
       " 'ص',\n",
       " 'ض',\n",
       " 'ط',\n",
       " 'ظ',\n",
       " 'ع',\n",
       " 'غ',\n",
       " 'ف',\n",
       " 'ق',\n",
       " 'ل',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ي',\n",
       " 'َ',\n",
       " 'ُ',\n",
       " 'ِ',\n",
       " 'ّ',\n",
       " 'ْ',\n",
       " 'ٔ',\n",
       " 'پ',\n",
       " 'چ',\n",
       " 'ژ',\n",
       " 'ک',\n",
       " 'گ',\n",
       " 'ی',\n",
       " '\\u200c']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aba77bd1-8517-4916-8e92-d03c14c1a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in combined_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b21fe6c-70e4-4eeb-9f02-11c6af5f5097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  ' ' :   0,\n",
      "  '!' :   1,\n",
      "  '(' :   2,\n",
      "  ')' :   3,\n",
      "  ',' :   4,\n",
      "  ':' :   5,\n",
      "  '\\xa0':   6,\n",
      "  '«' :   7,\n",
      "  '»' :   8,\n",
      "  '،' :   9,\n",
      "  '؛' :  10,\n",
      "  '؟' :  11,\n",
      "  'ء' :  12,\n",
      "  'آ' :  13,\n",
      "  'أ' :  14,\n",
      "  'ؤ' :  15,\n",
      "  'ئ' :  16,\n",
      "  'ا' :  17,\n",
      "  'ب' :  18,\n",
      "  'ت' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9041a110-de33-4898-9345-cfd7a82b13ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'به نام خداوند' ---- characters mapped to int ---- > [18 41  0 40 17 39  0 23 24 17 42 40 24]\n"
     ]
    }
   ],
   "source": [
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(combined_data[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f103fc0-66db-4e02-bf5b-ae22a484952d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ب\n",
      "ه\n",
      " \n",
      "ن\n",
      "ا\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74eff98a-ebb1-4dbd-a423-52266beea8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'به نام خداوند جان و خرد,کز این برتر اندیشه بر نگذرد,خداوند نام و خداوند جای,خداوند روزی ده رهنمای,خدا'\n",
      "***************\n",
      "'وند کیوان و گَردان سپهر,فروزندهٔ\\xa0ماه و ناهید و مهر,ز نام و نشان و گمان برتر است,نگارندهٔ بر شده پیکر '\n",
      "***************\n",
      "'است,به بینندگان آفریننده را,نبینی مرنجان دو بیننده را,نیابد بدو نیز اندیشه راه,که او برتر از نام و از'\n",
      "***************\n",
      "' جایگاه,سخن هر چه زین گوهران بگذرد,نیابد بدو راه جان و خرد,خرد گر سخن برگزیند همی,همان را گزیند، که ب'\n",
      "***************\n",
      "'یند همی,ستودن نداند کس، او را چو هست,میان بندگی را ببایدت بست,خرد را و جان را همی سنجد اوی,در اندیشهٔ'\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))\n",
    "    print(\"***\"*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1210e68e-d362-471b-99f8-1a63df9218f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d055a1d9-bdb9-485a-ab2b-69212b0403c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'به نام خداوند جان و خرد,کز این برتر اندیشه بر نگذرد,خداوند نام و خداوند جای,خداوند روزی ده رهنمای,خد'\n",
      "Target data: 'ه نام خداوند جان و خرد,کز این برتر اندیشه بر نگذرد,خداوند نام و خداوند جای,خداوند روزی ده رهنمای,خدا'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e79d1917-f5da-4e4d-a781-c06598e17ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 18 ('ب')\n",
      "  expected output: 41 ('ه')\n",
      "Step    1\n",
      "  input: 41 ('ه')\n",
      "  expected output: 0 (' ')\n",
      "Step    2\n",
      "  input: 0 (' ')\n",
      "  expected output: 40 ('ن')\n",
      "Step    3\n",
      "  input: 40 ('ن')\n",
      "  expected output: 17 ('ا')\n",
      "Step    4\n",
      "  input: 17 ('ا')\n",
      "  expected output: 39 ('م')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68614393-d707-45e9-9b64-5ee13827e8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7a4caab-c067-46c1-acfe-639602880d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "embedding_dim = 25\n",
    "\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60351e1f-49da-47de-a257-f2e6575bf313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "346d4460-a72f-486a-9f85-7c1178379705",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce23d676-c656-4eaf-8c45-49f03f09f420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 25)            1425      \n",
      "                                                                 \n",
      " gru (GRU)                   (64, None, 1024)          3228672   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 57)            58425     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3288522 (12.54 MB)\n",
      "Trainable params: 3288522 (12.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "763bd4f9-f641-4e7b-86ae-aed4e7c3880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a414d20e-dcaa-4c99-bc06-f25127b1dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b185309-87ed-4cec-95b0-83776e919d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "152eb560-af14-48ac-9a0b-5bdae7ddfb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 17:39:14.524870: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-05 17:39:14.593981: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f1fe1406fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-05 17:39:14.594005: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce MX330, Compute Capability 6.1\n",
      "2024-06-05 17:39:14.598417: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-05 17:39:14.624842: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717623554.664254    5942 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396/396 [==============================] - 83s 205ms/step - loss: 2.5469\n",
      "Epoch 2/5\n",
      "396/396 [==============================] - 84s 213ms/step - loss: 1.8907\n",
      "Epoch 3/5\n",
      "396/396 [==============================] - 157s 396ms/step - loss: 1.6211\n",
      "Epoch 4/5\n",
      "396/396 [==============================] - 246s 620ms/step - loss: 1.4819\n",
      "Epoch 5/5\n",
      "396/396 [==============================] - 239s 603ms/step - loss: 1.3969\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=5, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a6b82c4-2e5d-4467-84c1-d6520410a268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/ckpt_5'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc620c83-3bcd-4cad-8ecc-658675458549",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d7e8993-a309-412f-a31d-f8cbd3a27ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (1, None, 25)             1425      \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (1, None, 1024)           3228672   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, None, 57)             58425     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3288522 (12.54 MB)\n",
      "Trainable params: 3288522 (12.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c819e1f-8fe7-4e0e-aa1e-6100d80614a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 1000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the word returned by the model\n",
    "      predictions = predictions \n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted word as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d47c03d-ce70-4154-8f5b-d9bbfb0f952c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خدای سوار,که هامون بود آن جهان شهریار,ز هر گونه امرم پرشمرده شد سقل بود یاد,پسستلیده جه در زینهار,بیارم نباشد مرا کرد رای,اگر پرستیزی ز پروردگار,تو از دشمنستاشن تاهوار,همی‌دید شاه,ز من شاه هرگز نیک و نبند,چو رواشتشایاری آن پادشا را بدی,ببندی دو پرسیز و نر شاه باد,در باره گشتاسپ بر مخت ارم,مرا سر باه آن گزارین نشان,بدر بارگوها پراگنده درد,که او این سخن زرد گفتن نهان,پس از جوی بر گنج و از پادشست,همه گشته از خوب و زافون شویم,نیا مرد برنا و پر سبی بنبشیم,زبا تا به مرز گران راه جوی,کزان گوره‌آذرنگه برگرفت,بپاشید زان تخم و بوران بجست,چو از درد دیبای یزدان پاس,ز جز دادگان گوشت این کارشاه,ازین پس جهانی به خامش بغز,چو آمد به تاخندی و سور نو,چو آگاهی و خاک درمان نزد زبان,ز لشکر نبودیشاد یل ناگه کرد,همه سنکل,وه با روز آتش گناه,به خوبی فراوان سرآورده یاه,بیاره به دلش از پژندش بدام,کسی کردگار جهان زنده شاه,جهان رفت روز سیاوشیر کیه,بدو گفت گفت آنک با ا برنبد پناه دبیر,همان پهلوان یلاب آفرین,اگر تنگ شاهی که بد شاه گشت,سوی ماه خرادم بخوانمایه‌ام,یمان سر به سر بر یکی مهره اندر گلاز,که در آبیور آمد آن باگر\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"به نام خدا\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398de30c-54bb-40a2-9d02-4f53ce303797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
