{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ecd4aa-1ff5-4e9e-b6c4-0bc4797c0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '15'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e3fdf1-a992-4b7f-88f6-7015c2c8ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = pd.read_csv('shahname.csv', encoding='utf-8')\n",
    "column_data = file_path['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60068ca6-34da-4f62-93ae-95ba6835bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_ds = tf.data.Dataset.from_tensor_slices(column_data.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df1704ac-e125-4e0b-83c8-66cfd593c8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خداوند جان و خرد\n"
     ]
    }
   ],
   "source": [
    "for example in raw_data_ds.take(1):\n",
    "    print(example.numpy().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c9ac2fe-6682-4d39-85f7-9c0072781a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    s0 = tf.strings.regex_replace(input_data, 'ي', 'ی')\n",
    "    s1 = tf.strings.regex_replace(s0, '\\xa0', ' ')\n",
    "    s2 = tf.strings.regex_replace(s1, '\\u200c', ' ')\n",
    "    s3 = tf.strings.regex_replace(s2, 'آ', 'ا')\n",
    "    s4 = tf.strings.regex_replace(s3, 'َ', ' ')\n",
    "    s5 = tf.strings.regex_replace(s4, 'ُ', ' ')\n",
    "    s6 = tf.strings.regex_replace(s5, 'ِ', ' ')\n",
    "    s7 = tf.strings.regex_replace(s6, 'ة', 'ه')\n",
    "    s8 = tf.strings.regex_replace(s7, 'هٔ', 'ه')\n",
    "    s9 = tf.strings.regex_replace(s8, 'ك', 'ک')\n",
    "    s10 = tf.strings.regex_replace(s9, '؛', ' ')\n",
    "    s11 = tf.strings.regex_replace(s10, 'ّ', ' ')\n",
    "    s12 = tf.strings.regex_replace(s11, 'ْ', ' ')\n",
    "    s13 = tf.strings.regex_replace(s12, '،', ' ')\n",
    "    s14 = tf.strings.regex_replace(s13, 'ء', ' ')\n",
    "    s15 = tf.strings.regex_replace(s14, '«', ' ')\n",
    "    s16 = tf.strings.regex_replace(s15, '»', ' ')\n",
    "    s17 = tf.strings.regex_replace(s16, 'أ', 'ا')\n",
    "    s18 = tf.strings.regex_replace(s17, 'ؤ', 'و')\n",
    "    s19 = tf.strings.regex_replace(s18, '؟', ' ')\n",
    "    s20 = tf.strings.regex_replace(s19, '!', ' ')\n",
    "    s21 = tf.strings.regex_replace(s20, ':', ' ')\n",
    "    return tf.strings.regex_replace(s21, 'ئ', 'ی')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0437ee6-f112-4023-91bd-0b07ef5f57ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_ds = raw_data_ds.map(custom_standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9d1a3b2-967b-40a9-ae0d-bc9a78bfb973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  به نام خداوند جان و خرد\n",
      "Original:  کز این برتر اندیشه بر نگذرد\n"
     ]
    }
   ],
   "source": [
    "for text in raw_data_ds.take(2):\n",
    "    print(\"Original: \", text.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1b76f59-9437-4435-92f9-86dbe429f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "embedding_dim = 128\n",
    "sequence_length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eb1a2c0-be01-41f8-86d0-6eb5b4320a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (# of distinct words):  16918\n"
     ]
    }
   ],
   "source": [
    "vectorize_layer = layers.TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(raw_data_ds.batch(1024))\n",
    "\n",
    "vocab = vectorize_layer.get_vocabulary()\n",
    "print(\"Vocabulary size (# of distinct words): \", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd770e12-e1c9-4b2c-b07f-73e13a974381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1287 --->  خروشید\n",
      " 313 --->  امدند\n"
     ]
    }
   ],
   "source": [
    "print(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\n",
    "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e851079b-e025-4be4-9579-bdc01111e66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'و', 'به', 'که']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a11762f3-8cab-4d73-835c-34eab577a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b194f26-b4dc-4ac4-8564-71f5e0b771e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_sequences = raw_data_ds.map(lambda x: vectorize_layer(x))\n",
    "dataset = vectorized_sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d20c1a33-4304-461a-a757-9eb1dc550649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [  3  79 366 115]\n",
      "Target: [ 79 366 115   2]\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.batch(1).take(1):\n",
    "    print(\"Input:\", input_example.numpy()[0])\n",
    "    print(\"Target:\", target_example.numpy()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98798fe4-68e8-47d6-bd6a-4c732d985b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da52d06a-63b9-4166-8247-1822c237804c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, None), dtype=tf.int64, name=None), TensorSpec(shape=(64, None), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = (\n",
    "    dataset\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60286d2a-49f8-4561-8518-5712da446773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (64, 4)\n",
      "Target shape: (64, 4)\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input shape:\", input_example.shape)\n",
    "    print(\"Target shape:\", target_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13d0d88a-badc-49c6-8115-c775fd1673ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "embedding_dim = 25\n",
    "\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36687f6c-5dc9-429a-87c2-916f558bea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07f16c1a-4407-4090-b68a-66a5d9aa308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cc9e5e7-bb3b-4d10-8db9-7f3055f0375d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 25)            422950    \n",
      "                                                                 \n",
      " gru (GRU)                   (64, None, 1024)          3228672   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 16918)         17340950  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20992572 (80.08 MB)\n",
      "Trainable params: 20992572 (80.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e2305b8-4f4a-4fdd-b1b9-9bb5f9e70419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0179428c-6380-490f-9d04-e87560891883",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "805d90fc-f831-4f44-afdb-6dc861e9f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d914c77c-b032-4b0c-a1c3-ab47162c9e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 08:21:42.637803: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-06-08 08:21:42.674111: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fbd018babc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-08 08:21:42.674137: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce MX330, Compute Capability 6.1\n",
      "2024-06-08 08:21:42.678639: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-08 08:21:42.706551: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717849302.744840   15314 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1550/1550 [==============================] - 171s 109ms/step - loss: 6.3624\n",
      "Epoch 2/30\n",
      "1550/1550 [==============================] - 171s 110ms/step - loss: 5.3611\n",
      "Epoch 3/30\n",
      "1550/1550 [==============================] - 171s 111ms/step - loss: 4.6987\n",
      "Epoch 4/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 4.0707\n",
      "Epoch 5/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 3.5253\n",
      "Epoch 6/30\n",
      "1550/1550 [==============================] - 171s 110ms/step - loss: 3.1194\n",
      "Epoch 7/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 2.8351\n",
      "Epoch 8/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 2.6380\n",
      "Epoch 9/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 2.4979\n",
      "Epoch 10/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 2.3959\n",
      "Epoch 11/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 2.3148\n",
      "Epoch 12/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 2.2563\n",
      "Epoch 13/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 2.2002\n",
      "Epoch 14/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 2.1609\n",
      "Epoch 15/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 2.1246\n",
      "Epoch 16/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 2.0846\n",
      "Epoch 17/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 2.0593\n",
      "Epoch 18/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 2.0409\n",
      "Epoch 19/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 2.0165\n",
      "Epoch 20/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 2.0001\n",
      "Epoch 21/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 1.9768\n",
      "Epoch 22/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 1.9562\n",
      "Epoch 23/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 1.9471\n",
      "Epoch 24/30\n",
      "1550/1550 [==============================] - 171s 111ms/step - loss: 1.9310\n",
      "Epoch 25/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 1.9179\n",
      "Epoch 26/30\n",
      "1550/1550 [==============================] - 171s 110ms/step - loss: 1.9035\n",
      "Epoch 27/30\n",
      "1550/1550 [==============================] - 171s 111ms/step - loss: 1.8965\n",
      "Epoch 28/30\n",
      "1550/1550 [==============================] - 171s 111ms/step - loss: 1.8876\n",
      "Epoch 29/30\n",
      "1550/1550 [==============================] - 172s 111ms/step - loss: 1.8762\n",
      "Epoch 30/30\n",
      "1550/1550 [==============================] - 173s 112ms/step - loss: 1.8631\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=30, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48fc3773-00a5-48ee-b6fe-37f1021013a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/ckpt_30'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65ede063-08ca-4f9f-8dfc-372d94586a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a246106e-0a75-4f93-9477-02f97cef7aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (1, None, 25)             422950    \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (1, None, 1024)           3228672   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, None, 16918)          17340950  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20992572 (80.08 MB)\n",
      "Trainable params: 20992572 (80.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f82d9985-42b4-455f-865f-4af5a18535ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    num_generate = 100\n",
    "\n",
    "    input_eval = [vocab.index(s) for s in start_string.split()]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    temperature = 1.0\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(vocab[predicted_id])\n",
    "\n",
    "    return ' '.join(start_string.split() + text_generated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad36fee7-7701-43d5-9d68-651892c3fec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خدا و ز گفتار او ماند اندر جهان را به خون ریختن زخم او کرد نرم باش ان لشکر رومی گزیده سوار و پیاده ببستند با درد بدخواه و ما را نیستی هرچ باید که پیدا شد ان موبدان بند صد اشتر ز درگاه برخاست و اسان شود زین سپس راه هرمزد چون باد و بر ما گشادست راه و هم دوزخ ازو خاک دریا همی رفت تا پیش گرد دامن گرد جوشان دم او بر زاد فرخ زاد هرمزد با ما به افسون دل و بیست ماهوی زین و مردی و بی بن به خون ریختن لشکر اندر فراز امدند\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"به نام خدا\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
